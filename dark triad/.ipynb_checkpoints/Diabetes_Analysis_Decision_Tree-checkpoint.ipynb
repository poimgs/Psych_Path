{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "### Our Goal:\n",
    "To diagnostically predict whether a patient has diabetes.\n",
    "\n",
    "### To Explore:\n",
    "1. DecisionTreeClassifier\n",
    "2. BaggingClassifier\n",
    "3. AdaBoostClassifier\n",
    "4. RandomForestClassifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For Decision Tree implementation\n",
    "from scipy.stats import entropy\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "\n",
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split \n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "# load dataset\n",
    "df = pd.read_csv(\"Diabetes.csv\", header = None, names=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "#label is the result we trying to predict [1 = got diabetes, 0 = healthy]\n",
    "\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = df[feature_cols]          # Features, independent var\n",
    "y = df.label                  # Target variable, dependent var (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "# Random partitions\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tree\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the full tree\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "tree.export_graphviz(clf, out_file='tree.dot', feature_names=feature_cols) #produces dot file\n",
    "\n",
    "import pydot\n",
    "\n",
    "(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('full_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruning! basically stop the tree before it max. \n",
    "#Directly implement the DecisionTreeClassifier on the training set. To ensure pruning, we set the max_depth=4.\n",
    "#Prevents overfitting.. but how do we do know when is too much????\n",
    "\n",
    "dptree = DecisionTreeClassifier(max_depth=4)\n",
    "dptree.fit(X_train, y_train)\n",
    "\n",
    "#Test!\n",
    "# Get the predicted y array\n",
    "\n",
    "y_pred = dptree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "# possible parameters to pass in and default values:\n",
    "# SEE: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "# criterion = \"gini\" or \"entropy\"\n",
    "# max_depth: int (default, none -- go as deep)\n",
    "# min_samples_split: int (default 2), if use float, it will consider the value as a proportion -- relative to dataset I believe)\n",
    "\n",
    "for depth in range(1, 20):\n",
    "    \n",
    "    pred_sum = 0\n",
    "    \n",
    "    trials = 100\n",
    "    \n",
    "    for trial in range(0, trials):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) # 70% training and 30% test\n",
    "        \n",
    "        decision_tree_test = DecisionTreeClassifier(\n",
    "            max_depth = depth,\n",
    "        )\n",
    "\n",
    "        dt = decision_tree_test.fit(X_train,y_train)\n",
    "\n",
    "        dt_pred = dt.predict(X_test)\n",
    "        pred_sum += metrics.accuracy_score(y_test, dt_pred)\n",
    "    \n",
    "    print(\"Depth = \", depth , \"Average Accuracy:\", pred_sum/trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Bagging (with Decision Tree) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (number of trees trained) (i.e. weak learners)\n",
    "\n",
    "model = BaggingClassifier(n_estimators=200)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = metrics.confusion_matrix(y_pred, y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the accuracy of the result\n",
    "\n",
    "bagged_results = metrics.accuracy_score(y_pred, y_test)\n",
    "print(bagged_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AdaBoost (with Decision Tree) </h1>\n",
    "\n",
    "*Note that the default AdaBoost implementation in SKLearn is Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the AdaBoost classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=200, learning_rate = 0.1)  #if you change learning_rates/ tune the no of weak base classifier, the \n",
    "#final accuracy will change\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#SVC classifer takes long time to run BUT it actually gives a very high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = metrics.confusion_matrix(y_pred, y_test)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy of the result\n",
    "asr = metrics.accuracy_score(y_pred, y_test)\n",
    "print(asr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The bigger the learning rate the more emphathsis on older trees\n",
    "\n",
    "for learningrate in range(1, 8):\n",
    "    \n",
    "    pred_sum = 0\n",
    "    \n",
    "    trials = 20\n",
    "    \n",
    "    for trial in range(0, trials):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) # 70% training and 30% test\n",
    "        \n",
    "        decision_tree_test = AdaBoostClassifier(n_estimators=200, learning_rate = 0.3 ** learningrate)\n",
    "\n",
    "        dt = decision_tree_test.fit(X_train,y_train)\n",
    "\n",
    "        dt_pred = dt.predict(X_test)\n",
    "        \n",
    "        pred_sum += metrics.accuracy_score(y_test, dt_pred)\n",
    "    \n",
    "    print(\"learningrate = \", 0.3 ** learningrate)\n",
    "    print(\"Average Accuracy:\", pred_sum/trials)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1> Random Forest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Random Forest classifier.\n",
    "#n_estimator is the number of base classifiers (i.e. weak learners) number of trees you have\n",
    "#default is sqrt of the m var\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "#SVC classifer takes long time to run BUT it actually gives a very high accuracy\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put a trail loop inside \n",
    "for power in range(7):\n",
    "    \n",
    "    n_estimators = 5 ** power\n",
    "\n",
    "    random_forest_test = RandomForestClassifier(\n",
    "        n_estimators = n_estimators,\n",
    "        bootstrap = True,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    random_forest_test.fit(X_train, y_train)\n",
    "    y_pred = random_forest_test.predict(X_test)\n",
    "    print(\"Accuracy for n_estimators:\", n_estimators, \" is \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from your Seniors DA (The Pioneer Batch) : **Ding Yang, Linus Cheng, Tan Kin Meng, and Kaelyn** for these codes, which they used in their DAP sharing :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
