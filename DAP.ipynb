{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data in csv file using pandasb\n",
    "df = pd.read_csv('filtered_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813579</td>\n",
       "      <td>Mon Apr 06 22:20:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>starkissed</td>\n",
       "      <td>@LettyA ahh ive always wanted to see rent  lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467818603</td>\n",
       "      <td>Mon Apr 06 22:21:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kennypham</td>\n",
       "      <td>Sad, sad, sad. I don't know why but I hate thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467819650</td>\n",
       "      <td>Mon Apr 06 22:22:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>antzpantz</td>\n",
       "      <td>@Viennah Yay! I'm happy for you with your job!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag        user  \\\n",
       "0       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY      Karoli   \n",
       "1       0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY        coZZ   \n",
       "2       0  1467813579  Mon Apr 06 22:20:31 PDT 2009  NO_QUERY  starkissed   \n",
       "3       0  1467818603  Mon Apr 06 22:21:49 PDT 2009  NO_QUERY   kennypham   \n",
       "4       0  1467819650  Mon Apr 06 22:22:05 PDT 2009  NO_QUERY   antzpantz   \n",
       "\n",
       "                                                text  \n",
       "0  @nationwideclass no, it's not behaving at all....  \n",
       "1  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "2  @LettyA ahh ive always wanted to see rent  lov...  \n",
       "3  Sad, sad, sad. I don't know why but I hate thi...  \n",
       "4  @Viennah Yay! I'm happy for you with your job!...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove mentions, emails and links\n",
    "def removeAt(tweet):\n",
    "    words = tweet.split(' ')\n",
    "    return ' '.join(filter(lambda x: x and '@' not in x, words))\n",
    "\n",
    "def removeLinks(tweet):\n",
    "    words = tweet.split(' ')\n",
    "    return ' '.join(filter(lambda x: not ('http://' in x.lower() or 'https://' in x.lower()), words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply formulas to clean data\n",
    "df.text = df.text.apply(lambda x: removeAt(removeLinks(x.strip())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12gaBrowningGal', '15Stepz', '16_MileyCyrus', ..., 'zubinsaxena',\n",
       "       'zuppalizzle', 'zzzValzzz'], dtype=object)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of users that we removed (due to duplicates)\n",
    "duplicated = df.duplicated(subset='text', keep=False)\n",
    "pd.unique(df['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14524</th>\n",
       "      <td>0</td>\n",
       "      <td>1835705341</td>\n",
       "      <td>Mon May 18 06:34:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>12gaBrowningGal</td>\n",
       "      <td>Blind. Definitely. They aren't the smartest bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68041</th>\n",
       "      <td>0</td>\n",
       "      <td>2211076285</td>\n",
       "      <td>Wed Jun 17 12:24:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>12gaBrowningGal</td>\n",
       "      <td>I'm killing me too! I'm hungry now- Pie, Outdo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85046</th>\n",
       "      <td>0</td>\n",
       "      <td>2299986642</td>\n",
       "      <td>Tue Jun 23 13:35:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>12gaBrowningGal</td>\n",
       "      <td>My skeet game bites! I am not joking. I will h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203184</th>\n",
       "      <td>4</td>\n",
       "      <td>2071364168</td>\n",
       "      <td>Sun Jun 07 19:16:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>12gaBrowningGal</td>\n",
       "      <td>That's just because she trying to figure out w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207475</th>\n",
       "      <td>4</td>\n",
       "      <td>2178187758</td>\n",
       "      <td>Mon Jun 15 07:19:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>12gaBrowningGal</td>\n",
       "      <td>I am really not skilled enough to shoot trap. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target          id                          date      flag  \\\n",
       "14524        0  1835705341  Mon May 18 06:34:45 PDT 2009  NO_QUERY   \n",
       "68041        0  2211076285  Wed Jun 17 12:24:07 PDT 2009  NO_QUERY   \n",
       "85046        0  2299986642  Tue Jun 23 13:35:33 PDT 2009  NO_QUERY   \n",
       "203184       4  2071364168  Sun Jun 07 19:16:31 PDT 2009  NO_QUERY   \n",
       "207475       4  2178187758  Mon Jun 15 07:19:40 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \n",
       "14524   12gaBrowningGal  Blind. Definitely. They aren't the smartest bi...  \n",
       "68041   12gaBrowningGal  I'm killing me too! I'm hungry now- Pie, Outdo...  \n",
       "85046   12gaBrowningGal  My skeet game bites! I am not joking. I will h...  \n",
       "203184  12gaBrowningGal  That's just because she trying to figure out w...  \n",
       "207475  12gaBrowningGal  I am really not skilled enough to shoot trap. ...  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaned dataframe \n",
    "df.drop_duplicates(subset='text', keep=False, inplace=True)\n",
    "\n",
    "# sort dataframe by user \n",
    "df.sort_values(by='user', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary consolidating users and tweets to send to LIWC \n",
    "user_list = df['user'].tolist()\n",
    "tweets_list = df['text'].tolist()\n",
    "\n",
    "user_tweet_dic = {}\n",
    "\n",
    "for i in range(len(user_list)):\n",
    "    user = user_list[i]\n",
    "    tweet = tweets_list[i]\n",
    "    \n",
    "    if user not in user_tweet_dic:\n",
    "        user_tweet_dic[user] = []\n",
    "        user_tweet_dic[user].append(tweet)\n",
    "    else:\n",
    "        user_tweet_dic[user].append(tweet)\n",
    "        \n",
    "new_user_list = []\n",
    "new_combined_tweets_list = []\n",
    "\n",
    "for user, tweets in user_tweet_dic.items():\n",
    "    combined_tweets = ' '.join(tweets)\n",
    "    if len(combined_tweets.split(' ')) >= 100:\n",
    "        new_user_list.append(user)\n",
    "        new_combined_tweets_list.append(combined_tweets)\n",
    "    \n",
    "# Create a dataframe based on dictionary and exporting as a csv file\n",
    "consolidated_tweets_df = pd.DataFrame({'user': new_user_list, 'tweets': new_combined_tweets_list})\n",
    "consolidated_tweets_df.to_csv('consolidated_tweets_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "    Imagine the group taking that csv file and putting it through the LIWC software to get the output! :D\n",
    "    <br>\n",
    "    The output will be saved in a file called LIWC2015 Results (consolidated_tweets_df.csv).csv that will be imported later\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for the first 500 users \n",
    "first_500_users = consolidated_tweets_df['user'].unique()[:500]\n",
    "first_500_users_df = df[df['user'].isin(first_500_users)]\n",
    "\n",
    "# Creating a dictionary of user and their tweets \n",
    "user_tweet_dictionary = {}\n",
    "\n",
    "# Create a format that follows IBM Watson's format and saving it to the user_tweet_dictionary\n",
    "for index, row in first_500_users_df.iterrows():\n",
    "    user = row['user']\n",
    "    text = row['text']\n",
    "    \n",
    "    tweet = {}\n",
    "    \n",
    "    tweet['content'] = text\n",
    "    tweet['contenttype'] = 'text/plain'\n",
    "    tweet['language'] = 'en'\n",
    "    \n",
    "    if user not in user_tweet_dictionary:\n",
    "        user_tweet_dictionary[user] = {'contentItems': []}\n",
    "        user_tweet_dictionary[user]['contentItems'].append(tweet)\n",
    "    else:\n",
    "        user_tweet_dictionary[user]['contentItems'].append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "    The bottom few cells are commented out because we are using API calls to get the output, and after a certain number of calls, we will have to pay money!\n",
    "    <br>\n",
    "    Instead, we have saved the file called big5_df.csv that will also be imported later\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from ibm_watson import PersonalityInsightsV3\n",
    "# from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "# #API KEY provided on the service page \n",
    "# KEY = 'STximBrq6oOabT5yZteafZcbt3m6Xh6SUSVuWr3RW3V6'\n",
    "\n",
    "# # Authentication via IBM's IAM (Identity and Access Management)\n",
    "# authenticator = IAMAuthenticator(KEY)\n",
    "\n",
    "# # Creating a service instance\n",
    "# service = PersonalityInsightsV3(\n",
    "#     version='2017-10-13',\n",
    "#     authenticator=authenticator)\n",
    "\n",
    "# # Setting service endpoint \n",
    "# service.set_service_url('https://gateway.watsonplatform.net/personality-insights/api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a dictionary to store results from IBM Watson\n",
    "# results = {'User': [],\n",
    "#           'Openness': [],\n",
    "#           'Conscientiousness': [],\n",
    "#           'Extraversion': [],\n",
    "#           'Agreeableness': [],\n",
    "#           'Emotional range': []}\n",
    "\n",
    "# # creates profiles of users in user_tweet_dictionary and saves them to results\n",
    "# for user, tweets in user_tweet_dictionary.items():\n",
    "#     profile = service.profile(tweets, 'application/json', raw_scores=True, consumption_preferences=True).get_result()\n",
    "    \n",
    "#     results['User'].append(user)\n",
    "#     results['Openness'].append(profile['personality'][0]['raw_score'])\n",
    "#     results['Conscientiousness'].append(profile['personality'][1]['raw_score'])\n",
    "#     results['Extraversion'].append(profile['personality'][2]['raw_score'])\n",
    "#     results['Agreeableness'].append(profile['personality'][3]['raw_score'])\n",
    "#     results['Emotional range'].append(profile['personality'][4]['raw_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dataframe from results dictionary and save csv to use\n",
    "# big5_df = pd.DataFrame(results)\n",
    "# big5_df.to_csv('big5_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Emotional range</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12gaBrowningGal</td>\n",
       "      <td>0.764999</td>\n",
       "      <td>0.656144</td>\n",
       "      <td>0.548956</td>\n",
       "      <td>0.788804</td>\n",
       "      <td>0.439579</td>\n",
       "      <td>388</td>\n",
       "      <td>27.36</td>\n",
       "      <td>34.94</td>\n",
       "      <td>68.96</td>\n",
       "      <td>...</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15Stepz</td>\n",
       "      <td>0.748124</td>\n",
       "      <td>0.690716</td>\n",
       "      <td>0.564859</td>\n",
       "      <td>0.823930</td>\n",
       "      <td>0.410770</td>\n",
       "      <td>254</td>\n",
       "      <td>26.07</td>\n",
       "      <td>70.94</td>\n",
       "      <td>84.80</td>\n",
       "      <td>...</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16_MileyCyrus</td>\n",
       "      <td>0.672814</td>\n",
       "      <td>0.637773</td>\n",
       "      <td>0.525612</td>\n",
       "      <td>0.811025</td>\n",
       "      <td>0.563704</td>\n",
       "      <td>1164</td>\n",
       "      <td>21.04</td>\n",
       "      <td>64.42</td>\n",
       "      <td>58.80</td>\n",
       "      <td>...</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.15</td>\n",
       "      <td>13.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18percentgrey</td>\n",
       "      <td>0.789412</td>\n",
       "      <td>0.607883</td>\n",
       "      <td>0.528168</td>\n",
       "      <td>0.772518</td>\n",
       "      <td>0.461528</td>\n",
       "      <td>931</td>\n",
       "      <td>47.25</td>\n",
       "      <td>53.87</td>\n",
       "      <td>58.83</td>\n",
       "      <td>...</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19fischi75</td>\n",
       "      <td>0.706904</td>\n",
       "      <td>0.627109</td>\n",
       "      <td>0.447471</td>\n",
       "      <td>0.803232</td>\n",
       "      <td>0.518279</td>\n",
       "      <td>1707</td>\n",
       "      <td>48.43</td>\n",
       "      <td>48.83</td>\n",
       "      <td>63.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              User  Openness  Conscientiousness  Extraversion  Agreeableness  \\\n",
       "0  12gaBrowningGal  0.764999           0.656144      0.548956       0.788804   \n",
       "1          15Stepz  0.748124           0.690716      0.564859       0.823930   \n",
       "2    16_MileyCyrus  0.672814           0.637773      0.525612       0.811025   \n",
       "3    18percentgrey  0.789412           0.607883      0.528168       0.772518   \n",
       "4       19fischi75  0.706904           0.627109      0.447471       0.803232   \n",
       "\n",
       "   Emotional range    WC  Analytic  Clout  Authentic  ...  Comma  Colon  \\\n",
       "0         0.439579   388     27.36  34.94      68.96  ...   2.58   0.00   \n",
       "1         0.410770   254     26.07  70.94      84.80  ...   9.45   0.39   \n",
       "2         0.563704  1164     21.04  64.42      58.80  ...   3.26   0.52   \n",
       "3         0.461528   931     47.25  53.87      58.83  ...   4.83   0.64   \n",
       "4         0.518279  1707     48.43  48.83      63.95  ...   0.70   0.23   \n",
       "\n",
       "   SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0   0.00   0.52   12.37  0.52    0.0     3.61     0.00    0.00  \n",
       "1   0.00   1.18    0.39  1.57    0.0     4.33     1.57    0.00  \n",
       "2   0.00   2.15   13.57  0.43    0.0     1.37     0.26    1.03  \n",
       "3   0.75   1.61    2.26  1.93    0.0     3.22     1.29    2.26  \n",
       "4   0.00   3.10    1.64  3.87    0.0     0.00     2.58    3.81  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing both the outputs of LIWC and IBM Watson (Big 5)\n",
    "LIWC_df = pd.read_csv('LIWC2015 Results (consolidated_tweets_df.csv).csv')\n",
    "LIWC_df.drop(0, inplace=True)\n",
    "LIWC_df.drop(columns=['A', 'C'], inplace=True)\n",
    "LIWC_df.rename(columns={'B': 'User'}, inplace=True)\n",
    "big5_df = pd.read_csv('big5_df.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Merge dataframes together\n",
    "updated_df = pd.merge(big5_df, LIWC_df)\n",
    "updated_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
